{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training a Multilayer Perceptron.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/interviewBubble/TensorFlow-Tutorial/blob/master/Training_a_Multilayer_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIsl5x680VuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96c74c05-7c75-4046-9066-d0d1d72e9cd6"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQFzE_2OBTMX",
        "colab_type": "text"
      },
      "source": [
        "**Deep Learning with TensorFlow**\n",
        "\n",
        "***Coding session 2: Training a Multilayer Perceptron***\n",
        "\n",
        "Let's train a simple neural network that classifies handwritten digits using the MNIST dataset.\n",
        "Video will be uploaded later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIH0jrid2qeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(im, label):\n",
        "    im = tf.cast(im, tf.float32)\n",
        "    im = im / 127.5\n",
        "    im = im - 1\n",
        "    im = tf.reshape(im, [-1])\n",
        "    return im, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekLHLTGJBIGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_layer(data_tensor, num_threads=8, prefetch_buffer=100, batch_size=32):\n",
        "    with tf.variable_scope(\"data\"):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(data_tensor)\n",
        "        dataset = dataset.shuffle(buffer_size=60000).repeat()\n",
        "        dataset = dataset.map(preprocess_data, num_parallel_calls=num_threads)\n",
        "        dataset = dataset.batch(batch_size)\n",
        "        dataset = dataset.prefetch(prefetch_buffer)\n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "    return iterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYkofJWNETM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_layer, num_classes=10):\n",
        "    with tf.variable_scope(\"model\"):\n",
        "        net = tf.layers.dense(input_layer, 512)\n",
        "        net = tf.nn.relu(net)\n",
        "        net = tf.layers.dense(net, num_classes)\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5M8X2F9EmRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_functions(logits, labels, num_classes=10):\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "        target_prob = tf.one_hot(labels, num_classes)\n",
        "        total_loss = tf.losses.softmax_cross_entropy(target_prob, logits)\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNsLF6-ME-QT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizer_func(total_loss, global_step, learning_rate=0.1):\n",
        "    with tf.variable_scope(\"optimizer\"):\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "        optimizer = optimizer.minimize(total_loss, global_step=global_step)\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkHGg8TCHeCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_metric(logits, labels):\n",
        "    with tf.variable_scope(\"performance_metric\"):\n",
        "        preds = tf.argmax(logits, axis=1)\n",
        "        labels = tf.cast(labels, tf.int64)\n",
        "        corrects = tf.equal(preds, labels)\n",
        "        accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkLBVPZiHmlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(data_tensor):\n",
        "    global_step = tf.Variable(1, dtype=tf.int32, trainable=False, name=\"iter_number\")\n",
        "\n",
        "    # training graph\n",
        "    images, labels = data_layer(data_tensor).get_next()\n",
        "    logits = model(images)\n",
        "    loss = loss_functions(logits, labels)\n",
        "    optimizer = optimizer_func(loss, global_step)\n",
        "    accuracy = performance_metric(logits, labels)\n",
        "\n",
        "    # start training\n",
        "    num_iter = 10000\n",
        "    log_iter = 1000\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        streaming_loss = 0\n",
        "        streaming_accuracy = 0\n",
        "\n",
        "        for i in range(1, num_iter + 1):\n",
        "            _, loss_batch, acc_batch = sess.run([optimizer, loss, accuracy])\n",
        "            streaming_loss += loss_batch\n",
        "            streaming_accuracy += acc_batch\n",
        "            if i % log_iter == 0:\n",
        "                print(\"Iteration: {}, Streaming loss: {:.2f}, Streaming accuracy: {:.2f}\"\n",
        "                        .format(i, streaming_loss/log_iter, streaming_accuracy/log_iter))\n",
        "                streaming_loss = 0\n",
        "                streaming_accuracy = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeBcwM4fH1i-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "22c846f2-d40b-4f91-9857-0e523536a232"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # It's very easy to load the MNIST dataset through the Keras module.\n",
        "    # Keras is a high-level neural network API that has become a part of TensorFlow since version 1.2.\n",
        "    # Therefore, we don't need to install Keras separately.\n",
        "    # In the upcoming lectures we will also see how to load and preprocess custom data.\n",
        "    data_train, data_val = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # The training set has 60,000 samples where each sample is a 28x28 grayscale image.\n",
        "    # Each one of these samples have a single label Similarly the validation set has 10,000 images and corresponding labels.\n",
        "    # We can verify this by printing the shapes of the loaded tensors\n",
        "    print(data_train[0].shape, data_train[1].shape, data_val[0].shape, data_val[1].shape)\n",
        "\n",
        "    # Let the training begin!\n",
        "    train(data_tensor=data_train)\n",
        "\n",
        "    # Even after very few epochs, we got a model that can classify the handwritten digits in the training set\n",
        "    # with 98% accuracy. So far we haven't used the validation set at all.\n",
        "    # You might wonder why we need a separate validation set in the first place.\n",
        "    # The answer is to make sure that the model generalizes well to unseen data to have an idea of the actual performance of the model.\n",
        "    # We will talk about that in the next session."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0926 15:11:43.573565 140443163309952 deprecation.py:323] From <ipython-input-6-7137d265056a>:8: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0926 15:11:44.184497 140443163309952 deprecation.py:323] From <ipython-input-8-0c9f91e3d35d>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0926 15:11:44.189876 140443163309952 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0926 15:11:44.700848 140443163309952 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1000, Streaming loss: 0.41, Streaming accuracy: 0.87\n",
            "Iteration: 2000, Streaming loss: 0.19, Streaming accuracy: 0.94\n",
            "Iteration: 3000, Streaming loss: 0.14, Streaming accuracy: 0.96\n",
            "Iteration: 4000, Streaming loss: 0.12, Streaming accuracy: 0.96\n",
            "Iteration: 5000, Streaming loss: 0.10, Streaming accuracy: 0.97\n",
            "Iteration: 6000, Streaming loss: 0.09, Streaming accuracy: 0.97\n",
            "Iteration: 7000, Streaming loss: 0.09, Streaming accuracy: 0.97\n",
            "Iteration: 8000, Streaming loss: 0.08, Streaming accuracy: 0.98\n",
            "Iteration: 9000, Streaming loss: 0.07, Streaming accuracy: 0.98\n",
            "Iteration: 10000, Streaming loss: 0.06, Streaming accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkzuBWn-ILuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}